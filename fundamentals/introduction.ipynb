{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TonyQ2k3/pytorch-deeplearning/blob/main/fundamentals/introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWkz3UlUcreN"
      },
      "source": [
        "# Introduction to Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda"
      ],
      "metadata": {
        "id": "-nDOqRONcseo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Data\n",
        "PyTorch has 2 primitives to work with data: `torch.utils.data.Dataset` and `torch.utils.data.DataLoader`.\n",
        "\n",
        "`Dataset` contains data and labels, `DataLoader` turns it into an iterable so we can work with them."
      ],
      "metadata": {
        "id": "HU-8kPo-FUsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "  root='data',\n",
        "  train=True,\n",
        "  transform=ToTensor(),\n",
        "  download=True\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    transform=ToTensor(),\n",
        "    download=True\n",
        ")"
      ],
      "metadata": {
        "id": "idI5xebQc7J3",
        "outputId": "798e5760-4d37-4104-8b30-dc543b1bb325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 309kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.50MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)"
      ],
      "metadata": {
        "id": "aJLTORM1dnFF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x_flattened = self.flatten(x)\n",
        "    logits = self.stack(x_flattened)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "ouWTqV8FeFkH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparams\n",
        "## Epochs: Number of times the dataset is passed through the model\n",
        "## Batch size: Number of samples the model sees each epochs\n",
        "## Step size (learning rate): Steps the model take to find a better weight. Too small => Take long time; Too large => May skip the best weight\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "# Loss func\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Dfp52PPFfELe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Calculate loss\n",
        "    y_preds = model(X)\n",
        "    loss = loss_fn(y_preds, y)\n",
        "\n",
        "    # Optimizing\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Testing\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      y_preds = model(X)\n",
        "      test_loss += loss_fn(y_preds, y).item()\n",
        "      correct += (y_preds.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= size\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "lMp1fnkYhnkK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "JCbR9z0EoE58",
        "outputId": "3cc73727-f68e-4ca2-bf90-efd4b4afabcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301724  [    0/60000]\n",
            "loss: 2.299560  [ 6400/60000]\n",
            "loss: 2.286786  [12800/60000]\n",
            "loss: 2.282403  [19200/60000]\n",
            "loss: 2.273354  [25600/60000]\n",
            "loss: 2.262784  [32000/60000]\n",
            "loss: 2.275910  [38400/60000]\n",
            "loss: 2.250309  [44800/60000]\n",
            "loss: 2.244017  [51200/60000]\n",
            "loss: 2.240890  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 0.034972 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.242568  [    0/60000]\n",
            "loss: 2.230204  [ 6400/60000]\n",
            "loss: 2.185237  [12800/60000]\n",
            "loss: 2.190307  [19200/60000]\n",
            "loss: 2.175929  [25600/60000]\n",
            "loss: 2.159860  [32000/60000]\n",
            "loss: 2.202749  [38400/60000]\n",
            "loss: 2.151306  [44800/60000]\n",
            "loss: 2.151529  [51200/60000]\n",
            "loss: 2.142649  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 0.033171 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.154103  [    0/60000]\n",
            "loss: 2.120513  [ 6400/60000]\n",
            "loss: 2.025701  [12800/60000]\n",
            "loss: 2.047816  [19200/60000]\n",
            "loss: 2.023637  [25600/60000]\n",
            "loss: 2.006219  [32000/60000]\n",
            "loss: 2.090317  [38400/60000]\n",
            "loss: 2.006603  [44800/60000]\n",
            "loss: 2.028480  [51200/60000]\n",
            "loss: 2.014532  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 0.030790 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.040636  [    0/60000]\n",
            "loss: 1.978423  [ 6400/60000]\n",
            "loss: 1.831186  [12800/60000]\n",
            "loss: 1.884330  [19200/60000]\n",
            "loss: 1.858026  [25600/60000]\n",
            "loss: 1.843576  [32000/60000]\n",
            "loss: 1.979436  [38400/60000]\n",
            "loss: 1.876438  [44800/60000]\n",
            "loss: 1.918872  [51200/60000]\n",
            "loss: 1.903267  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 45.0%, Avg loss: 0.028555 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.923528  [    0/60000]\n",
            "loss: 1.854981  [ 6400/60000]\n",
            "loss: 1.650839  [12800/60000]\n",
            "loss: 1.745160  [19200/60000]\n",
            "loss: 1.731451  [25600/60000]\n",
            "loss: 1.648916  [32000/60000]\n",
            "loss: 1.845461  [38400/60000]\n",
            "loss: 1.686474  [44800/60000]\n",
            "loss: 1.783464  [51200/60000]\n",
            "loss: 1.799613  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 49.0%, Avg loss: 0.026464 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"data/model.pth\")\n",
        "\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "id": "B9nl1aatoRFd",
        "outputId": "399e97d2-d001-4604-9946-66cbd1b718fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and running model"
      ],
      "metadata": {
        "id": "U9IszTp4pTFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the model to evaluation mode is important\n",
        "+ **Dropout layers** disable some activation neurons to prevent overfitting. Setting this to eval will allows all neurons to be used.\n",
        "+ **Batch normalization** layer computes the mean and variance of batch data during training, setting this to eval will allow these statistics to be used."
      ],
      "metadata": {
        "id": "PjyWNyiHBOgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = NeuralNetwork()\n",
        "new_model.load_state_dict(torch.load('data/model.pth'))\n",
        "\n",
        "# Calling eval() before inferencing to set the dropout & batch normalization to evaluation mode\n",
        "new_model.eval()"
      ],
      "metadata": {
        "id": "2b1JizBw_hvW",
        "outputId": "4d46df66-819f-4c9f-f6d7-52f5c04c29fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e037dbd45f0f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  new_model.load_state_dict(torch.load('data/model.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (5): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h-GZzeelDWm8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}